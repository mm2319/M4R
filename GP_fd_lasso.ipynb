{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "import pandas\n",
    "import derivative\n",
    "from lorenz import create_data_lorenz\n",
    "from non_linear import create_data_nonlinear\n",
    "from two_compartment import create_data_twocompart\n",
    "from Derivative_Data_Lorenz import obtain_train_data_Lorenz\n",
    "from Derivative_Data_NonLinear import obtain_train_data_NonLinear\n",
    "from Derivative_Data_Two_Compart import obtain_train_data_Two_compart\n",
    "from Bayesian_Regression_Disc_Spike_and_Slab import Bayesian_regression_disc_spike_slab\n",
    "from Bayesian_Regression_Cont_Spike_and_Slab import Bayesian_regression_conti_spike_slab\n",
    "from Bayesian_Regression_SS_Selection_2 import Bayesian_regression_SS_Selction\n",
    "from Gaussian_process_der import GP, GP_derivative,rbf,rbf_fd,rbf_pd_2,rbf_pd_1,RBF_partial_diff_first,RBF_partial_diff_second\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence\n",
    "from scipy.optimize import minimize\n",
    "import autograd.numpy as np\n",
    "from autograd import value_and_grad\n",
    "from skopt.plots import plot_convergence\n",
    "np.random.seed(0)\n",
    "gp = GP(kernel=rbf,kernel_diff=rbf_fd)\n",
    "para_two_compart_1 = np.load('gp_000_para_tc_1.npy')\n",
    "para_two_compart_2 = np.load('gp_000_para_tc_2.npy')\n",
    "para_nonlinear_1  = np.load('gp_000_para_nl_1.npy')\n",
    "para_nonlinear_2 = np.load('gp_000_para_nl_2.npy')\n",
    "para_lorenz_1 =np.load('gp_000_para_lorenz_1.npy')\n",
    "para_lorenz_2 =np.load('gp_000_para_lorenz_2.npy')\n",
    "para_lorenz_3 =np.load('gp_000_para_lorenz_3.npy')\n",
    "# finds the hyperparameters for two_compart\n",
    "T, Y_tc = create_data_twocompart(p=0.0)\n",
    "Y_compart = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.1),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_tc[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_two_compart_1[0],para_two_compart_1[1]],\n",
    "              sigma=para_two_compart_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.1),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_tc[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_two_compart_2[0],para_two_compart_2[1]],\n",
    "              sigma=para_two_compart_2[2]\n",
    "              )\n",
    "Y_compart.append(y_pred_1)\n",
    "Y_compart.append(y_pred_2)\n",
    "Y_compart = np.array(Y_compart).T\n",
    "\n",
    "\n",
    "# finds the hyperparameters for nonlinear\n",
    "T, Y_nl = create_data_nonlinear(p=0.0)\n",
    "Y_nonlinear = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.1),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_nl[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_nonlinear_1[0],para_nonlinear_1[1]],\n",
    "              sigma=para_nonlinear_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.1),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_nl[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_nonlinear_2[0],para_nonlinear_2[1]],\n",
    "              sigma=para_nonlinear_2[2]\n",
    "              )\n",
    "Y_nonlinear.append(y_pred_1)\n",
    "Y_nonlinear.append(y_pred_2)\n",
    "Y_nonlinear = np.array(Y_nonlinear).T\n",
    "\n",
    "\n",
    "# finds the hyperparameters for lorenz\n",
    "T, Y_lr = create_data_lorenz(p=0.0)\n",
    "Y_lorenz = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.1),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_1[0],para_lorenz_1[1]],\n",
    "              sigma=para_lorenz_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.1),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_2[0],para_lorenz_2[1]],\n",
    "              sigma=para_lorenz_2[2]\n",
    "              )\n",
    "y_pred_3 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.1),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,2]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_3[0],para_lorenz_3[1]],\n",
    "              sigma=para_lorenz_3[2]\n",
    "              )\n",
    "Y_lorenz.append(y_pred_1)\n",
    "Y_lorenz.append(y_pred_2)\n",
    "Y_lorenz.append(y_pred_3)\n",
    "Y_lorenz= np.array(Y_lorenz).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_1 = derivative.dxdt(Y_compart[:,0], np.arange(0,10,0.1), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_compart[:,1], np.arange(0,10,0.1), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train  = obtain_train_data_Two_compart( result_1, result_2, num_samples = 100, Y = Y_compart)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "\n",
    "np.save('gpfd_ls_000_tc_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_000_tc_2',list(clf_2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = derivative.dxdt(Y_nonlinear[:,0], np.arange(0,10,0.1), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_nonlinear[:,1], np.arange(0,10,0.1), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train  = obtain_train_data_NonLinear( result_1, result_2, num_samples = 100, Y = Y_nonlinear)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "\n",
    "\n",
    "np.save('gpfd_ls_000_nl_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_000_nl_2',list(clf_2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = derivative.dxdt(Y_lorenz[:,0], np.arange(0,10,0.1), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_lorenz[:,1], np.arange(0,10,0.1), kind=\"finite_difference\", k=2)\n",
    "result_3 = derivative.dxdt(Y_lorenz[:,2], np.arange(0,10,0.1), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train, x_3_train, y_3_train = obtain_train_data_Lorenz( result_1, result_2, result_3, num_samples = 100, y = Y_lorenz)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_3 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "clf_3.fit(x_3_train, y_3_train)\n",
    "\n",
    "\n",
    "np.save('gpfd_ls_000_lr_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_000_lr_2',list(clf_2.coef_))\n",
    "np.save('gpfd_ls_000_lr_3',list(clf_3.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "gp = GP(kernel=rbf,kernel_diff=rbf_fd)\n",
    "para_two_compart_1 = np.load('gp_001_para_tc_1.npy')\n",
    "para_two_compart_2 = np.load('gp_001_para_tc_2.npy')\n",
    "para_nonlinear_1  = np.load('gp_001_para_nl_1.npy')\n",
    "para_nonlinear_2 = np.load('gp_001_para_nl_2.npy')\n",
    "para_lorenz_1 =np.load('gp_001_para_lorenz_1.npy')\n",
    "para_lorenz_2 =np.load('gp_001_para_lorenz_2.npy')\n",
    "para_lorenz_3 =np.load('gp_001_para_lorenz_3.npy')\n",
    "# finds the hyperparameters for two_compart\n",
    "T, Y_tc = create_data_twocompart(p=0.01)\n",
    "Y_compart = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_tc[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_two_compart_1[0],para_two_compart_1[1]],\n",
    "              sigma=para_two_compart_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_tc[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_two_compart_2[0],para_two_compart_2[1]],\n",
    "              sigma=para_two_compart_2[2]\n",
    "              )\n",
    "Y_compart.append(y_pred_1)\n",
    "Y_compart.append(y_pred_2)\n",
    "Y_compart = np.array(Y_compart).T\n",
    "\n",
    "\n",
    "# finds the hyperparameters for nonlinear\n",
    "T, Y_nl = create_data_nonlinear(p=0.01)\n",
    "Y_nonlinear = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_nl[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_nonlinear_1[0],para_nonlinear_1[1]],\n",
    "              sigma=para_nonlinear_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_nl[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_nonlinear_2[0],para_nonlinear_2[1]],\n",
    "              sigma=para_nonlinear_2[2]\n",
    "              )\n",
    "Y_nonlinear.append(y_pred_1)\n",
    "Y_nonlinear.append(y_pred_2)\n",
    "Y_nonlinear = np.array(Y_nonlinear).T\n",
    "\n",
    "\n",
    "# finds the hyperparameters for lorenz\n",
    "T, Y_lr = create_data_lorenz(p=0.01)\n",
    "Y_lorenz = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_1[0],para_lorenz_1[1]],\n",
    "              sigma=para_lorenz_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_2[0],para_lorenz_2[1]],\n",
    "              sigma=para_lorenz_2[2]\n",
    "              )\n",
    "y_pred_3 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,2]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_3[0],para_lorenz_3[1]],\n",
    "              sigma=para_lorenz_3[2]\n",
    "              )\n",
    "Y_lorenz.append(y_pred_1)\n",
    "Y_lorenz.append(y_pred_2)\n",
    "Y_lorenz.append(y_pred_3)\n",
    "Y_lorenz= np.array(Y_lorenz).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_1 = derivative.dxdt(Y_compart[:,0], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_compart[:,1], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train  = obtain_train_data_Two_compart( result_1, result_2, num_samples = 100, Y = Y_compart)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "\n",
    "np.save('gpfd_ls_001_tc_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_001_tc_2',list(clf_2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = derivative.dxdt(Y_nonlinear[:,0], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_nonlinear[:,1], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train  = obtain_train_data_NonLinear( result_1, result_2, num_samples = 100, Y = Y_nonlinear)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "\n",
    "\n",
    "np.save('gpfd_ls_001_nl_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_001_nl_2',list(clf_2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = derivative.dxdt(Y_lorenz[:,0], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_lorenz[:,1], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "result_3 = derivative.dxdt(Y_lorenz[:,2], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train, x_3_train, y_3_train = obtain_train_data_Lorenz( result_1, result_2, result_3, num_samples = 100, y = Y_lorenz)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_3 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "clf_3.fit(x_3_train, y_3_train)\n",
    "\n",
    "\n",
    "np.save('gpfd_ls_001_lr_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_001_lr_2',list(clf_2.coef_))\n",
    "np.save('gpfd_ls_001_lr_3',list(clf_3.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "gp = GP(kernel=rbf,kernel_diff=rbf_fd)\n",
    "para_two_compart_1 = np.load('gp_025_para_tc_1.npy')\n",
    "para_two_compart_2 = np.load('gp_025_para_tc_2.npy')\n",
    "para_nonlinear_1  = np.load('gp_025_para_nl_1.npy')\n",
    "para_nonlinear_2 = np.load('gp_025_para_nl_2.npy')\n",
    "para_lorenz_1 =np.load('gp_025_para_lorenz_1.npy')\n",
    "para_lorenz_2 =np.load('gp_025_para_lorenz_2.npy')\n",
    "para_lorenz_3 =np.load('gp_025_para_lorenz_3.npy')\n",
    "# finds the hyperparameters for two_compart\n",
    "T, Y_tc = create_data_twocompart(p=0.25)\n",
    "Y_compart = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_tc[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_two_compart_1[0],para_two_compart_1[1]],\n",
    "              sigma=para_two_compart_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_tc[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_two_compart_2[0],para_two_compart_2[1]],\n",
    "              sigma=para_two_compart_2[2]\n",
    "              )\n",
    "Y_compart.append(y_pred_1)\n",
    "Y_compart.append(y_pred_2)\n",
    "Y_compart = np.array(Y_compart).T\n",
    "\n",
    "\n",
    "# finds the hyperparameters for nonlinear\n",
    "T, Y_nl = create_data_nonlinear(p=0.25)\n",
    "Y_nonlinear = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_nl[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_nonlinear_1[0],para_nonlinear_1[1]],\n",
    "              sigma=para_nonlinear_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_nl[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_nonlinear_2[0],para_nonlinear_2[1]],\n",
    "              sigma=para_nonlinear_2[2]\n",
    "              )\n",
    "Y_nonlinear.append(y_pred_1)\n",
    "Y_nonlinear.append(y_pred_2)\n",
    "Y_nonlinear = np.array(Y_nonlinear).T\n",
    "\n",
    "\n",
    "# finds the hyperparameters for lorenz\n",
    "T, Y_lr = create_data_lorenz(p=0.25)\n",
    "Y_lorenz = []\n",
    "y_pred_1 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,0]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_1[0],para_lorenz_1[1]],\n",
    "              sigma=para_lorenz_1[2]\n",
    "              )\n",
    "y_pred_2 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,1]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_2[0],para_lorenz_2[1]],\n",
    "              sigma=para_lorenz_2[2]\n",
    "              )\n",
    "y_pred_3 = gp.predict_mean(\n",
    "              x_star=np.arange(0,10,0.01),  # set to test points\n",
    "              X = np.array(T),     # set to observed x\n",
    "              y = np.array(Y_lr[:,2]),       # set to observed y\n",
    "              size=1,    # draw 100 posterior samples \n",
    "              theta=[para_lorenz_3[0],para_lorenz_3[1]],\n",
    "              sigma=para_lorenz_3[2]\n",
    "              )\n",
    "Y_lorenz.append(y_pred_1)\n",
    "Y_lorenz.append(y_pred_2)\n",
    "Y_lorenz.append(y_pred_3)\n",
    "Y_lorenz= np.array(Y_lorenz).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_1 = derivative.dxdt(Y_compart[:,0], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_compart[:,1], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train  = obtain_train_data_Two_compart( result_1, result_2, num_samples = 100, Y = Y_compart)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "\n",
    "np.save('gpfd_ls_025_tc_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_025_tc_2',list(clf_2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = derivative.dxdt(Y_nonlinear[:,0], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_nonlinear[:,1], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train  = obtain_train_data_NonLinear( result_1, result_2, num_samples = 100, Y = Y_nonlinear)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "\n",
    "\n",
    "np.save('gpfd_ls_025_nl_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_025_nl_2',list(clf_2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = derivative.dxdt(Y_lorenz[:,0], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "result_2 = derivative.dxdt(Y_lorenz[:,1], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "result_3 = derivative.dxdt(Y_lorenz[:,2], np.arange(0,10,0.01), kind=\"finite_difference\", k=2)\n",
    "\n",
    "x_1_train, y_1_train, x_2_train, y_2_train, x_3_train, y_3_train = obtain_train_data_Lorenz( result_1, result_2, result_3, num_samples = 100, y = Y_lorenz)\n",
    "\n",
    "clf_1 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_2 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "clf_3 = linear_model.LassoCV(alphas=[1.e-3, 1.e-2, 1.e-1, 1., 10, 100], max_iter=50000, fit_intercept=False)\n",
    "\n",
    "clf_1.fit(x_1_train, y_1_train)\n",
    "clf_2.fit(x_2_train, y_2_train)\n",
    "clf_3.fit(x_3_train, y_3_train)\n",
    "\n",
    "\n",
    "np.save('gpfd_ls_025_lr_1',list(clf_1.coef_))\n",
    "np.save('gpfd_ls_025_lr_2',list(clf_2.coef_))\n",
    "np.save('gpfd_ls_025_lr_3',list(clf_3.coef_))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
